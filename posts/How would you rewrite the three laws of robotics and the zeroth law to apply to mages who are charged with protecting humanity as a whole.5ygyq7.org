#+TITLE: How would you rewrite the three laws of robotics and the zeroth law to apply to mages who are charged with protecting humanity as a whole?

* How would you rewrite the three laws of robotics and the zeroth law to apply to mages who are charged with protecting humanity as a whole?
:PROPERTIES:
:Author: viol8er
:Score: 8
:DateUnix: 1489085947.0
:DateShort: 2017-Mar-09
:FlairText: Discussion
:END:

** Please elaborate. Are you talking about some kind of magical vow that would enforce those rules?

The biggest issue I see right now is that if you just replace robots with wizards they would assume some kind of subservient role for Muggles which might or might not be what you want?
:PROPERTIES:
:Author: Deathcrow
:Score: 4
:DateUnix: 1489087112.0
:DateShort: 2017-Mar-09
:END:

*** u/metaridley18:
#+begin_quote
  The biggest issue I see right now is that if you just replace robots with wizards they would assume some kind of subservient role for Muggles which might or might not be what you want?
#+end_quote

Well the whole point of the novels about the three laws was that even if they seem fool proof the wording can be subverted and twisted so as to defy the point so I doubt mages would end up truly subservient.
:PROPERTIES:
:Author: metaridley18
:Score: 1
:DateUnix: 1489087461.0
:DateShort: 2017-Mar-09
:END:


*** I saw it more as a subset of mages who've elected to follow a set of guidelines thay can be easily subverted when need be BUT look like they're enforceable at a quick glance. These mages would protect all sophonts by any means necessary which means that if x needs to die, then x will, even if a-w and y and zed get burnt from orbit ad well.

It's just a noodling idea i got while cleaning the house and prepping for an estate sale after gran's death.

Edit: lately, i've really been obsessed with writing about what seems to be benevolent fascism but is very much totalianarism. It's disturbing me.
:PROPERTIES:
:Author: viol8er
:Score: 1
:DateUnix: 1489089529.0
:DateShort: 2017-Mar-09
:END:


** The laws of robotics were written to be enforced over subservient beings who were not believe to actually have a conscience. Applying them to humanity would require a total rewrite. Of course the fact that the laws of robotics are subverted relatively easily becomes the whole point of them existing in the first place. The entire point of the three laws is that they do not work.

A more interesting question, perhaps, would be applying something like say, The Laws of Magic from The Dresden Files to the question rather than the laws of Robotics. Although it's probably a bit more of an esoteric question.
:PROPERTIES:
:Author: TE7
:Score: 3
:DateUnix: 1489088097.0
:DateShort: 2017-Mar-09
:END:

*** The Laws of Robotics applied to House Elves would probably work after a fashion if one wished to pen a HP/Asimov fusion.
:PROPERTIES:
:Author: __Pers
:Score: 1
:DateUnix: 1489173637.0
:DateShort: 2017-Mar-10
:END:


** For those who are unsure what those are:

- Zeroth law: A robot may not harm humanity, or, by inaction, allow humanity to come to harm

- First: A robot may not injure a human being or, through inaction, allow a human being to come to harm.

- Second: A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.

- Third: A robot must protect its own existence as long as such protection does not conflict with the First or Second Laws

To rewrite them for some sort of mage-unit, maybe this is a good start. As I would presume that such an organisation would be more charitable, I assume they include sentients in their sphere of protection.

- 0: A Mage may not harm the societies of sentients, or, by inaction, allow the societies of sentients to come to harm.

However, here we have the main problem. Depending on their morals this can mean a variety of things. Are they Utilitarianists? Are they Kantists? Are they Marxists? Or something completely different? The question is "What does harm to sentient societies, and what doesn't?" How do they decide between them?

- 1: A mage may not injure a sentient being or, through inaction, allow a human being to come to harm.

- 2: A mage must obey the orders of his superior, except where such orders would conflict with the zeroth and first law.

- 3: A mage must seek to prolong, guard and improve his existence as long as such actions do not conflict with the zeroth, first or second Law

This third one is also interesting. The robotic law says that the robot must remain functioning. I would argue that in order to remain functioning, a sentient being must seek to progress. At least humans do not do well in ever-same repetition. How this law would apply to your mages, I don't know.

Also, as some already said: the Laws written by Asimov are made for machines.
:PROPERTIES:
:Author: UndeadBBQ
:Score: 2
:DateUnix: 1489088362.0
:DateShort: 2017-Mar-09
:END:

*** I think it would be humanity as a whole versus people as singular for 1. They'd be a secret society still but guarding humanity. Like the world that took away all pain from at least one other world in the foundationverse.
:PROPERTIES:
:Author: viol8er
:Score: 1
:DateUnix: 1489099739.0
:DateShort: 2017-Mar-10
:END:

**** I've unfortunately never read Asimov, so no idea what you'Re talking about with your comparison.

But I guess they'd be more the SHIELD type of organisation, to use another fandom. Rather indifferent about the single life, but constantly working to keep humanity as a whole alive and well.

What kind of fic did you think about? Harry joining them?

You wrote you're obsessed with writing "benevolent" fascism / totalitarianism lately. Would that organisation have governmental power?

Anyway, can you tell me more? I'm always interested in some worldbuilding.
:PROPERTIES:
:Author: UndeadBBQ
:Score: 1
:DateUnix: 1489132484.0
:DateShort: 2017-Mar-10
:END:


** Wot in robotnation
:PROPERTIES:
:Author: GroovinChip
:Score: 2
:DateUnix: 1489096607.0
:DateShort: 2017-Mar-10
:END:


** That's pretty easy. You just extrapolate the Unforgivables. Don't kill, don't torture, and don't mind control.
:PROPERTIES:
:Author: Dorgamund
:Score: 1
:DateUnix: 1489129042.0
:DateShort: 2017-Mar-10
:END:


** A thing I've been wondering about with the Three Laws of Robotics (brought on by reading Bryon Nightshade's work) is, if robots are built by humans, and have the ability to see, hear, touch, smell, walk around, et-cetera...

The thing is, robots will observe the world around them, and use what they observe in their decision making. But their senses and mobility were built into them by humans, precisely so they could accomplish that decision making. Doesn't that mean that 'observe the world around you and make decisions based on what you observe' counts as a human order, under the 2nd law? In that case, what if a human order conflicts with a robot's decisions? Do they follow the most recent order given to them, or their first 'order' to observe and make choices?

** 
   :PROPERTIES:
   :CUSTOM_ID: section
   :END:
If you applied the same thinking to mages, with the same laws, they'd probably hit the same thing too.

"Look, buddo, if you didn't want me having a brain and making my own decisions, maybe you should have asked my mother to not have kids."

** 
   :PROPERTIES:
   :CUSTOM_ID: section-1
   :END:
...Anyway, yeah, if you want to write new ones, maybe go with what Dorgamund said, base them off the unforgivable curses? Although I'd probably base rules more off intelligence and/or emotional capability/value than just life, swatting flies or slaughtering cows for meat isn't the same thing as killing humans or centaurs or whatnot.
:PROPERTIES:
:Author: Avaday_Daydream
:Score: 1
:DateUnix: 1489140784.0
:DateShort: 2017-Mar-10
:END:


** A robot must not ever follow a self created directive.

Fin.
:PROPERTIES:
:Score: 0
:DateUnix: 1489122246.0
:DateShort: 2017-Mar-10
:END:

*** I find your flair to be highly amusing.
:PROPERTIES:
:Author: NanlteSystems
:Score: 1
:DateUnix: 1489240614.0
:DateShort: 2017-Mar-11
:END:
