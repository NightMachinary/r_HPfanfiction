:PROPERTIES:
:Author: wokste1024
:Score: 3
:DateUnix: 1501251941.0
:DateShort: 2017-Jul-28
:END:

The problem is more difficult than you might imagine at first. First, sapience is not a binary thing. In fact, it is not well defined. Something can be somewhat sapient (dog-level AI) or very sapient (surpassing humans). They may not have the same emotions as humans and may think differently.

They may not have a physical body but exist in data-centers in the worlds. They can be copy-pasted. How does the right change then? Do back-ups have the right to live as well or can they be kept frozen? Are we allowed to modify an AI to improve it? What if the AI desires things we don't want (any-more)? Are we allowed to discriminate if a category of AI's malfunction?

Personally, I believe giving sapient AI's the same rights as humans is short-sighted and may give more problems as it solves. I do believe they should have rights and duties, based on how advanced they are. This will be a major challenge based on the diversity of AI's.